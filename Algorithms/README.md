# Algorithms

*  [Attention Distillation](#Attention-Distillation)
*  [Adversarial Distillation](#Adversarial-Distillation)
*  [Multi-teacher Distillation](#Multi-teacher-Distillation)
*  [Cross-modal Distillation](#Cross-modal-Distillation)
*  [Graph-based Distillation](#Graph-based-Distillation)
*  [Adaptive Distillation](#Adaptive-Distillation)
*  [Contrastive Distillation](#Contrastive-Distillation)
---
## Attention Distillation

## Adversarial Distillation

## Multi-teacher Distillation

## Cross-modal Distillation

* Cross Modal Distillation for Supervision Transfer - 2016 - [paper](http://openaccess.thecvf.com/content_cvpr_2016/html/Gupta_Cross_Modal_Distillation_CVPR_2016_paper.html) - [code](https://github.com/s-gupta/fast-rcnn)
* Modality distillation with multiple stream networks for action recognition - 2018 - [paper](http://openaccess.thecvf.com/content_ECCV_2018/html/Nuno_Garcia_Modality_Distillation_with_ECCV_2018_paper.html) - [code](https://github.com/ncgarcia/modality-distillation)
* Learning with Privileged Information via Adversarial Discriminative Modality Distillation - 2019 - [paper](https://ieeexplore.ieee.org/abstract/document/8764498/) - [code](https://github.com/pmorerio/admd)
* Cross-Modal Knowledge Distillation for Action Recognition - 2019 - [paper](https://ieeexplore.ieee.org/abstract/document/8802909/)
* 3D-to-2D Distillation for Indoor Scene Parsing - 2021 - [paper](https://openaccess.thecvf.com/content/CVPR2021/html/Liu_3D-to-2D_Distillation_for_Indoor_Scene_Parsing_CVPR_2021_paper.html?ref=https://githubhelp.com) - [code](https://github.com/liuzhengzhe/3D-to-2D-Distillation-for-Indoor-Scene-Parsing)
* EvDistill: Asynchronous Events To End-Task Learning via Bidirectional Reconstruction-Guided Cross-Modal Knowledge Distillation - 2021 - [paper](http://openaccess.thecvf.com/content/CVPR2021/html/Wang_EvDistill_Asynchronous_Events_To_End-Task_Learning_via_Bidirectional_Reconstruction-Guided_Cross-Modal_CVPR_2021_paper.html) - [code](https://github.com/addisonwang2013/evdistill)
* Cross-Modality Knowledge Distillation Network for Monocular 3D Object Detection - 2022 - [paper](https://link.springer.com/chapter/10.1007/978-3-031-20080-9_6) - [code](https://github.com/Cc-Hy/CMKD)
* Robust Cross-Modal Representation Learning with Progressive Self-Distillation - 2022 - [paper](http://openaccess.thecvf.com/content/CVPR2022/html/Andonian_Robust_Cross-Modal_Representation_Learning_With_Progressive_Self-Distillation_CVPR_2022_paper.html) 
* UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View - 2023 - [paper](http://openaccess.thecvf.com/content/CVPR2023/html/Zhou_UniDistill_A_Universal_Cross-Modality_Knowledge_Distillation_Framework_for_3D_Object_CVPR_2023_paper.html) - [code](https://github.com/megvii-research/cvpr2023-unidistill)
* DistillBEV: Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation - 2023 - [paper](http://openaccess.thecvf.com/content/ICCV2023/html/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.html) - [code](https://github.com/qcraftai/distill-bev)
* X3KD: Knowledge Distillation Across Modalities, Tasks and Stages for Multi-Camera 3D Object Detection - 2023 - [paper](http://openaccess.thecvf.com/content/CVPR2023/html/Klingner_X3KD_Knowledge_Distillation_Across_Modalities_Tasks_and_Stages_for_Multi-Camera_CVPR_2023_paper.html)
* Efficient RGB-T Tracking via Cross-Modality Distillation  - 2023 - [paper](http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Efficient_RGB-T_Tracking_via_Cross-Modality_Distillation_CVPR_2023_paper.html)
* Decomposed Cross-Modal Distillation for RGB-Based Temporal Action Detection - 2023 - [paper](http://openaccess.thecvf.com/content/CVPR2023/html/Lee_Decomposed_Cross-Modal_Distillation_for_RGB-Based_Temporal_Action_Detection_CVPR_2023_paper.html)
* STXD: structural and temporal cross-modal distillation for multi-view 3D object detection - 2023 - [paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/5d8c01de2dc698c54201c1c7d0b86974-Abstract-Conference.html) 
* C2KD: Bridging the Modality Gap for Cross-Modal Knowledge Distillation - 2024 - [paper](http://openaccess.thecvf.com/content/CVPR2024/html/Huo_C2KD_Bridging_the_Modality_Gap_for_Cross-Modal_Knowledge_Distillation_CVPR_2024_paper.html)
* CRKD: Enhanced Camera-Radar Object Detection with Cross-modality Knowledge Distillation - 2024 - [paper](http://openaccess.thecvf.com/content/CVPR2024/html/Zhao_CRKD_Enhanced_Camera-Radar_Object_Detection_with_Cross-modality_Knowledge_Distillation_CVPR_2024_paper.html)
* Xkd: Cross-modal knowledge distillation with domain alignment for video representation learning - 2024 - [paper](https://ojs.aaai.org/index.php/AAAI/article/view/29407) - [code](https://github.com/pritamqu/XKD)
* Radocc: Learning cross-modality occupancy knowledge through rendering assisted distillation - 2024 - [paper](https://ojs.aaai.org/index.php/AAAI/article/view/28533) 
* CM-MaskSD: Cross-Modality Masked Self-Distillation for Referring Image Segmentation - 2024 - [paper](https://ieeexplore.ieee.org/abstract/document/10413654/)
* On the Theory of Cross-Modality Distillation with Contrastive Learning - 2024 - [paper](https://ui.adsabs.harvard.edu/abs/2024arXiv240503355L/abstract)


## Graph-based Distillation

## Adaptive Distillation

## Contrastive Distillation
* Dimensionality Reduction by Learning an Invariant Mapping - 2006 - [paper](https://ieeexplore.ieee.org/abstract/document/1640964)
* Contrastive Representation Distillation - 2019 - [paper](https://arxiv.org/abs/1910.10699) - [code](https://github.com/HobbitLong/RepDistiller)
* Wasserstein Contrastive Representation Distillation - 2021 - [paper](https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Wasserstein_Contrastive_Representation_Distillation_CVPR_2021_paper.html)
* Augmentation-Free Dense Contrastive Knowledge Distillation for Efficient Semantic Segmentation - 2023 - [paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a12779b5e802668df1cbc73fa00da62f-Abstract-Conference.html) - [code](https://github.com/OSVAI/Af-DCD)
* Knowledge Distillation for Single Image Super-Resolution via Contrastive Learning - 2024 - [paper](https://dl.acm.org/doi/abs/10.1145/3652583.3657606)
* ComKD-CLIP: Comprehensive Knowledge Distillation for Contrastive Language-Image Pre-traning Model - 2024 - [paper](https://arxiv.org/abs/2408.04145)
* DistilCSE: Effective Knowledge Distillation For Contrastive Sentence Embeddings - 2021 - [paper](https://arxiv.org/abs/2112.05638)
* Categorical Relation-Preserving Contrastive Knowledge Distillation for Medical Image Classification - 2021 - [paper](https://link.springer.com/chapter/10.1007/978-3-030-87240-3_16) - [code](https://github.com/hathawayxxh/CRCKD)
* Improving Weakly Supervised Visual Grounding by Contrastive Knowledge Distillation - 2021 - [paper](https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Improving_Weakly_Supervised_Visual_Grounding_by_Contrastive_Knowledge_Distillation_CVPR_2021_paper.html) - [code](https://github.com/jhuang81/weak-sup-visual-grounding)
* Complementary Relation Contrastive Distillation - 2021 - [paper](https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Complementary_Relation_Contrastive_Distillation_CVPR_2021_paper.html) - [code](https://github.com/Lechatelia/CRCD)
